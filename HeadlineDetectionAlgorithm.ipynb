{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeadlineDetectionAlgorithm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanyhmahadi/Fake-News-Detection/blob/master/HeadlineDetectionAlgorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn6cNtVWyJKW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCZkvlPxU0ZZ"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_excel(\"/content/drive/MyDrive/Research/NLP/Sentiment Data/FakevsAuthentic news edit sany.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33Oz3l2QnzZx"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFoboq7BGk1B"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rlacHHSEdXM"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEZ9HVuk4W5d"
      },
      "source": [
        "len(df[df.Label=='Fake'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmxBYl4BqMz6"
      },
      "source": [
        "len(df[df.Label=='Authentic'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GsM2whotScA"
      },
      "source": [
        "df.Label = df.Label.replace({'Authentic': 1, 'Fake': 0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGJrnOs_Gx5L"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE2019TMBn21"
      },
      "source": [
        "df['Headline'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nppBP-bJlxH"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nO0fvlzG971"
      },
      "source": [
        "df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-59mGfLJ3gM"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"Serial:\",i+1)\n",
        "    print(\"Text:\",df.Headline[i])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79LU_o6jMkPZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kotRMLBNMucF"
      },
      "source": [
        "df['Label'].plot(kind='hist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqP40tKRwuVl"
      },
      "source": [
        "stas = ['Authentic', 'Fake']\n",
        "\n",
        "data = [237,206]\n",
        "\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.pie(data, labels = stas)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5KjEW9WNEVe"
      },
      "source": [
        "df['length'] = df['Headline'].str.split().apply(len)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiNLTSASObsQ"
      },
      "source": [
        "df.hist(column='length', by='Label', bins=50,figsize=(10,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LPkPO7NPr9F"
      },
      "source": [
        "df.length.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q_M3De81h6U"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import math\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, log_loss, cohen_kappa_score, roc_auc_score, roc_curve\n",
        "from sklearn import metrics\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Hq-Z5ILBFA"
      },
      "source": [
        "import string \n",
        "def remove_punc(s):\n",
        "    table = str.maketrans({key: None for key in string.punctuation})\n",
        "    return s.translate(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFw0-Xw1FNDw"
      },
      "source": [
        "x = df['Headline'].fillna(' ')\n",
        "y = df['Label']\n",
        "print(x.head())\n",
        "print(y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrWbwzbCLI84"
      },
      "source": [
        "x = df['Headline'].apply(remove_punc)\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VtnWPku9wjd"
      },
      "source": [
        "contractions = { \n",
        "\"বি.দ্র \": \"বিশেষ দ্রষ্টব্য\",\n",
        "\"ড.\": \"ডক্টর\",\n",
        "\"ডা.\": \"ডাক্তার\",\n",
        "\"ইঞ্জি:\": \"ইঞ্জিনিয়ার\",\n",
        "\"রেজি:\": \"রেজিস্ট্রেশন\",\n",
        "\"মি.\": \"মিস্টার\",\n",
        "\"মু.\": \"মুহাম্মদ\",\n",
        "\"মো.\": \"মোহাম্মদ\",\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8clNtSHSIl8"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "vocab = Counter()\n",
        "def clean_text(x,remove_stopwords = True):\n",
        "    if True:\n",
        "        new_text = []\n",
        "        for word in x:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        x = \" \".join(new_text)\n",
        "    # Format words and remove unwanted characters\n",
        "    whitespace = re.compile(u\"[\\s\\u0020\\u00a0\\u1680\\u180e\\u202f\\u205f\\u3000\\u2000-\\u200a]+\", re.UNICODE)\n",
        "    bangla_digits = u\"[\\u09E6\\u09E7\\u09E8\\u09E9\\u09EA\\u09EB\\u09EC\\u09ED\\u09EE\\u09EF]+\"\n",
        "    english_chars = u\"[a-zA-Z0-9]\"\n",
        "    punc = u\"[(),$%^&*+={}\\[\\]:\\\"|\\'\\~`<>/,¦!?½£¶¼©⅐⅑⅒⅓⅔⅕⅖⅗⅘⅙⅚⅛⅜⅝⅞⅟↉¤¿º;-]+\"\n",
        "    bangla_fullstop = u\"\\u0964\"     #bangla fullstop(dari)\n",
        "    punctSeq   = u\"['\\\"“”‘’]+|[.?!,…]+|[:;]+\"\n",
        "    \n",
        "    x = re.sub(bangla_digits, \" \", x)\n",
        "    x = re.sub(punc, \" \", x)\n",
        "    x = re.sub(english_chars, \" \", x)\n",
        "    x = re.sub(bangla_fullstop, \" \", x)\n",
        "    x = re.sub(punctSeq, \" \", x)\n",
        "    x = whitespace.sub(\" \", x).strip()\n",
        "    \n",
        "    x = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE)\n",
        "    x = re.sub(r'\\<a href', ' ', x)\n",
        "    x = re.sub(r'&amp;‘:‘ ’', '', x) \n",
        "    x = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]। ,', ' ', x)\n",
        "    x = re.sub(r'<br />', ' ', x)\n",
        "    x = re.sub(r'\\'', ' ', x)\n",
        "    x = re.sub(r\"[\\@$#%~+-\\.\\'।\\\"]\",\" \",x)\n",
        "    x = re.sub(r\"(?m)^\\s+\", \"\", x)\n",
        "    x = re.sub(\"[()]\",\"\",x)\n",
        "    x = re.sub(\"[‘’]\",\"\",x)\n",
        "    x = re.sub(\"[!]\",\"\",x)\n",
        "    x = re.sub(\"[/]\",\"\",x)\n",
        "    x = re.sub(\"[:]\",\"\",x)\n",
        "    x = re.sub('\\ |\\?|\\.|\\!|\\/|\\;|\\:', ' ',x)\n",
        "    x = x.strip(\"/\")\n",
        "    \n",
        "    if remove_stopwords:\n",
        "        k = []\n",
        "        with open('/content/drive/MyDrive/Research/NLP/Banglastopword.txt', 'r',encoding=\"utf-8\") as f:\n",
        "            for word in f:\n",
        "                word = word.split()\n",
        "                k.append(word[0])\n",
        "            x = [t for t in x if t not in k]\n",
        "            x = \"\".join(x)\n",
        "   \n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqpjMzwppjce"
      },
      "source": [
        "vocab = CountVectorizer(ngram_range=(1,1),analyzer='word',encoding='utf-8').fit(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVpQ5VJPpjob"
      },
      "source": [
        "print(vocab.vocabulary_)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "x = vocab.transform(x) \n",
        "print(x.toarray())\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(vocab.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVOJGnW8sTD6"
      },
      "source": [
        "print(\"Shape of the sparse matrix: \", x.shape)\n",
        "print(\"Non-Zero occurences: \",x.nnz)\n",
        "density = (x.nnz/(x.shape[0]*x.shape[1]))*100\n",
        "print(\"Density of the matrix = \",density)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsaEyphFGkPC"
      },
      "source": [
        "**Train Test & Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWj40yR0sTGH"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dt4ec54sTIZ"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(x_train,y_train)\n",
        "print('Confusion matrix of model is :')\n",
        "cm = confusion_matrix(y_test,mnb.predict(x_test))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "result1 = classification_report(y_test, mnb.predict(x_test))\n",
        "print(\"Classification Report : \",)\n",
        "print (result1)\n",
        "print()\n",
        "var1 = ((TP + TN)/(TP + TN + FP + FN)) *100\n",
        "print('Testing accuracy : ',var1)\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,mnb.predict(x_test)))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, mnb.predict(x_test)))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,mnb.predict(x_test))))\n",
        "print('Log_Loss:', metrics.log_loss(y_test,mnb.predict(x_test)))\n",
        "print('Cohen_Kappa_Score:', cohen_kappa_score(y_test, mnb.predict(x_test)))\n",
        "\n",
        "print()\n",
        "print()\n",
        "name = ['Multinomial Naive Bayes']\n",
        "col_value = ['#95a5a6']\n",
        "model_accuracy = pd.Series(data=[var1], index=[name[0]])\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "width = 0.75 \n",
        "model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[0]])\n",
        "plt.xticks(rotation=0)\n",
        "plt.title('Model Accracy')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()\n",
        "print()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57e4diOWsTNm"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rmfr = RandomForestClassifier()\n",
        "rmfr.fit(x_train,y_train)\n",
        "print('Confusion matrix of model is :')\n",
        "cm = confusion_matrix(y_test,rmfr.predict(x_test))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "result1 = classification_report(y_test, rmfr.predict(x_test))\n",
        "print(\"Classification Report : \",)\n",
        "print (result1)\n",
        "print()\n",
        "var2 = ((TP + TN)/(TP + TN + FP + FN)) *100\n",
        "print('Testing accuracy : ',var2)\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,rmfr.predict(x_test)))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, rmfr.predict(x_test)))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,rmfr.predict(x_test))))\n",
        "print('Log_Loss:', metrics.log_loss(y_test,rmfr.predict(x_test)))\n",
        "print('Cohen_Kappa_Score:', cohen_kappa_score(y_test, rmfr.predict(x_test)))\n",
        "\n",
        "print()\n",
        "print()\n",
        "name = ['RandomForest']\n",
        "col_value = ['red']\n",
        "model_accuracy = pd.Series(data=[var2], index=[name[0]])\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "width = 0.75 \n",
        "model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[0]])\n",
        "plt.xticks(rotation=0)\n",
        "plt.title('Model Accracy')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()\n",
        "print()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zQL4TM1srq4"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train,y_train)\n",
        "print('Confusion matrix of model is :')\n",
        "cm = confusion_matrix(y_test,dt.predict(x_test))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "result1 = classification_report(y_test, dt.predict(x_test))\n",
        "print(\"Classification Report : \",)\n",
        "print (result1)\n",
        "print()\n",
        "var3 = ((TP + TN)/(TP + TN + FP + FN)) *100\n",
        "print('Testing accuracy : ',var3)\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,dt.predict(x_test)))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, dt.predict(x_test)))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,dt.predict(x_test))))\n",
        "print('Log_Loss:', metrics.log_loss(y_test,dt.predict(x_test)))\n",
        "print('Cohen_Kappa_Score:', cohen_kappa_score(y_test, dt.predict(x_test)))\n",
        "\n",
        "print()\n",
        "print()\n",
        "name = ['DecisionTree']\n",
        "col_value = ['#9b59b6']\n",
        "model_accuracy = pd.Series(data=[var3], index=[name[0]])\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "width = 0.75 \n",
        "model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[0]])\n",
        "plt.xticks(rotation=0)\n",
        "plt.title('Model Accracy')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()\n",
        "print()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-MuS53ksr27"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "svm = SVC()\n",
        "svm.fit(x_train,y_train)\n",
        "print('Confusion matrix of model is :')\n",
        "cm = confusion_matrix(y_test,svm.predict(x_test))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "result1 = classification_report(y_test, svm.predict(x_test))\n",
        "print(\"Classification Report : \",)\n",
        "print (result1)\n",
        "print()\n",
        "var4 = ((TP + TN)/(TP + TN + FP + FN)) *100\n",
        "print('Testing accuracy : ',var4)\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,svm.predict(x_test)))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, svm.predict(x_test)))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,svm.predict(x_test))))\n",
        "print('Log_Loss:', metrics.log_loss(y_test,svm.predict(x_test)))\n",
        "print('Cohen_Kappa_Score:', cohen_kappa_score(y_test, svm.predict(x_test)))\n",
        "\n",
        "print()\n",
        "print()\n",
        "name = ['Support Vector Clasiffier']\n",
        "col_value = ['blue']\n",
        "model_accuracy = pd.Series(data=[var4], index=[name[0]])\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "width = 0.75 \n",
        "model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[0]])\n",
        "plt.xticks(rotation=0)\n",
        "plt.title('Model Accracy')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()\n",
        "print()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWLhJXzis3-w"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(x_train,y_train)\n",
        "print('Confusion matrix of model is :')\n",
        "cm = confusion_matrix(y_test,knn.predict(x_test))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "result1 = classification_report(y_test, knn.predict(x_test))\n",
        "print(\"Classification Report : \",)\n",
        "print (result1)\n",
        "print()\n",
        "var5 = ((TP + TN)/(TP + TN + FP + FN)) *100\n",
        "print('Testing accuracy : ',var5)\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,knn.predict(x_test)))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, knn.predict(x_test)))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,knn.predict(x_test))))\n",
        "print('Log_Loss:', metrics.log_loss(y_test,knn.predict(x_test)))\n",
        "print('Cohen_Kappa_Score:', cohen_kappa_score(y_test, knn.predict(x_test)))\n",
        "\n",
        "print()\n",
        "print()\n",
        "name = ['K-NN']\n",
        "col_value = ['#7fcdbb']\n",
        "model_accuracy = pd.Series(data=[var5], index=[name[0]])\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "width = 0.75 \n",
        "model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[0]])\n",
        "plt.xticks(rotation=0)\n",
        "plt.title('Model Accracy')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()\n",
        "print()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPpEYFlF0R_4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "l = LogisticRegression()\n",
        "l.fit(x_train,y_train)\n",
        "logi=l.score(x_test,  y_test)\n",
        "print('Confusion matrix of model',i , 'is :')\n",
        "cm = confusion_matrix(y_test,l.predict(x_test))\n",
        "TP = cm[0][0]\n",
        "TN = cm[1][1]\n",
        "FP = cm[0][1]\n",
        "FN = cm[1][0]\n",
        "print(cm)\n",
        "print()\n",
        "result1 = classification_report(y_test, l.predict(x_test))\n",
        "print(\"Classification Report : \",)\n",
        "print (result1)\n",
        "print()\n",
        "var6 = ((TP + TN)/(TP + TN + FP + FN)) *100\n",
        "print('Testing accuracy : ',var6)\n",
        "print('Sensitivity : ', TP/(TP+FN))\n",
        "print('Specificity : ', TN/(TN+FP))\n",
        "print('false positive rate : ', FP/(FP+TN))\n",
        "print('false negative rate : ', FN/(FN+TP))\n",
        "print('Negative Predictive Value : ', TN/(TN+FN))\n",
        "print('False Discovery rate : ', FP/(TP+FP))\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,l.predict(x_test)))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, l.predict(x_test)))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,l.predict(x_test))))\n",
        "print('Log_Loss:', metrics.log_loss(y_test,l.predict(x_test)))\n",
        "print('Cohen_Kappa_Score:', cohen_kappa_score(y_test, l.predict(x_test)))\n",
        "\n",
        "print()\n",
        "print()\n",
        "name = ['Logistic Regression']\n",
        "col_value = ['#2ecc71']\n",
        "model_accuracy = pd.Series(data=[var6], index=[name[0]])\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "width = 0.75 \n",
        "model_accuracy.sort_values().plot.bar(alpha=0.8, color=[col_value[0]])\n",
        "plt.xticks(rotation=0)\n",
        "plt.title('Model Accracy')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()\n",
        "print()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgcu14rc0dcs"
      },
      "source": [
        "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "objects = ('MNB','RF','DT','SVC','KNN','logi')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [var1,var2,var3,var4,var5,var6]\n",
        " \n",
        "plt.bar(y_pos, performance, align='center', alpha=0.9)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Best Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsl1CsvHs-4G"
      },
      "source": [
        "# news=input()\n",
        "# prt=vocab.transform([news])\n",
        "\n",
        "# m1=mnb.predict(prt)\n",
        "# print(\"MNV Predicted Rating:\",m1)\n",
        "# if m1==0:\n",
        "#   print(\"No\")\n",
        "# else:\n",
        "#   print(\"yes\")\n",
        "\n",
        "# m2=rmfr.predict(prt)\n",
        "# print(\"RF Predicted Rating:\",m2)\n",
        "# if m2==0:\n",
        "#   print(\"No\")\n",
        "# else: \n",
        "#   print(\"yes\")\n",
        "\n",
        "\n",
        "# m3=dt.predict(prt)\n",
        "# print(\"DT Predicted Rating:\",m3)\n",
        "# if m3==0:\n",
        "#   print(\"No\")\n",
        "# else:\n",
        "#   print(\"yes\")\n",
        "\n",
        "\n",
        "# m4=svm.predict(prt)\n",
        "# print(\"SVM Predicted Rating:\",m4)\n",
        "# if m4==0:\n",
        "#   print(\"No\")\n",
        "# else:\n",
        "#   print(\"Yes\")\n",
        "\n",
        "# m5=knn.predict(prt)\n",
        "# print(\"KNN Predicted Rating:\",m4)\n",
        "# if m4==0:\n",
        "#   print(\"No\")\n",
        "# else:\n",
        "#   print(\"Yes\")\n",
        "\n",
        "\n",
        "#   m6=l.predict(prt)\n",
        "# print(\"Logistic Predicted Rating:\",m4)\n",
        "# if m4==0:\n",
        "#   print(\"No\")\n",
        "# else:\n",
        "#   print(\"Yes\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}